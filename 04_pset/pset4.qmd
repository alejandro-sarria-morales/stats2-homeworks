---
title: "Pset 4: Multiple regression"
author: "Alejandro Sarria"
format: pdf
---

# Part 1

## 1.

a.  We find the error by plugging in the values for X and Y in observation A (2 and 9, respectively) and solving for the error term in the data generating formula.

9 = 2 + 3\*2 + error

9 - 2 - 6 = error

1 = error

b.  Solving the regression equation for the error results in the residual.

9 =  1.9 + 3.1*2 + error

9 - 1.9 - 6.2 = error

0.9 = error

Then, the residual of observation A is 0.9

## 2.

-   Top left: Y \~ X + D

-   Top right: Y \~ X

-   Bottom left: Y \~ X 

-   Bottom right: Y \~ X

## 3.

a.  When controlling for children under 5, the model estimates 76.18 more hours of work each year per unit increase in years of education.

b.  When controlling for years of education, the standard error for children under 5 is 19.28

c.  In the third model, the predicted work hours for a woman with 0 years of education and 0 children under 5 is 306.55

d.  In the second model, a woman with 2 children and 10 years of education would be estimate to work 778.965 hours per year.

e.  To calculate the "statistical significance" of children under 5 we need to calculate the t-statistic (coefficient / std. error of coefficient).

```{r}
model2_t <- -238.853 / 19.693
model3_t <- -251.181 / 19.28

print(model2_t)
print(model3_t)
```

In both models, the t-statistic for children under 5 is well below -1.96, meaning that they are both statistically significant.

## 4.

a. A one year increase in education the number of hours worked in a year by the derivative of the model, that is: $110.230 - 3.162(Edu)$.

b. $110.230 - 3.162(16) = 59.638$

c. It gets less positive as the number of years of education increases as $\beta_2Edu^2$ will eventually be higher than $\beta_1$ (110.230).

d. As we add more polynomials to the model, we risk overfitting  to the sample data, loosing validity when comparing to the population.

## 5. 

a. The coefficient suggests that homeowners work 50.174 more hours per year than non-homeowners. The t-statistic for Model 1 is 1.52, leaving it below the threshold for statistical significance (1.96).

```{r}
50.174/32.923
```

b. People with 4 children under the age of 5 work 150.592 less than people with 3.

c. The table alone is not enough to tell. One way to test it would be to run a new model including both having 2 and having 3 children under 5 and looking at the significance of each variable.

## 6.

a. In the model, a unit increase in education predicts an increase of $110.073 - 53.994Homeowner$

b. The interaction term shows that the effect of education on hours worked is 110.073 for non-homeowners and 56.079 for homeowners.

c. A one unit increase in Education predicts a 6.93% increase in hours worked.

d. A 1% increase in education predicts a $832.347*Log(1.01) = 8.28$ increase in hours worked.

e. Applying a log transformation requires the value for Hours Worked to be higher than 0 as log0 is undefined. The reduction in the number of observations for model 2 may be a result of removing cases in which there were no hours worked.

## 7.

b. When error terms are correlated across time, such that knowing the error term in one period gives us some information about the error term in the next period.

## 8. 

b. Creating a plot with Y on the y-axis and X on the x-axis, and a line reflecting the predicted values of the regression, and seeing if the spread of the values around the predicted values change over the range of X.

c.

e.

## 9.

The researchers could apply weights the observations in the sample so that the underrepresented sectors of the population have a higher weight in the analysis.

## 10.

a. You’re doing research on unusual sexual practices. You ask people whether they’ve ever engaged in these practices, which many people might prefer to keep secret, even if they’ve actually done them.

# Part 2. 

## 1.

```{r}
library(tidyverse)
d <- read.csv("dengue.csv")
model1 <- lm(NoYes ~ humid + temp,
             data = d)
summary(model1)
```

## 2.
```{r}
library(marginaleffects)
model2 <- glm(NoYes ~ humid + temp,
             data = d,
             family = binomial(link = "logit"))
summary(model2)
avg_slopes(model2)
```

In the logit model, a unit increase in humid increases the probability of observing dengue by 3.173% while a unit increase in temperature increases the probability by 0.415%.

## 3.

```{r}
d <- d |> 
  filter(!is.na(humid))

model3 <- lm(humid ~ temp,
             data = d)
summary(model3)

d <- d |> 
  mutate(res = model3$residuals)

ggplot(d, aes(x=temp,y=res)) +
  geom_point(alpha=.5)
``` 

There seems to be heteroskedasticity, the variance of the residuals increases as temperature rises.

```{r}
model4 <- fixest::feols(humid ~ temp,
             data = d,
             se = "hetero")
summary(model4)
```

There was little change in the standard errors of the model using heteroskedasticity-robust standard errors so there might have been much issue to begin with.

## 4. 

```{r}
model5 <- fixest::feols(log(humid) ~ temp,
             data = d,
             se = "hetero")
summary(model5)
```

In this model, a unit increase in temperature is associated with a $100*(e^{0.056}-1)=5.76$ percent increase in humidity.

## 5.

The relationship between humidity and temperature is exponential (this can be seen in the last graph). Applying a logarithmic transformation to humidity "reverses" the exponential relationship, making it linear.
